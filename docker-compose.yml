# DocVision Docker Compose
# ========================
# Development and production configurations

services:
  # Development server (CPU)
  docvision-dev:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    volumes:
      - ./data:/app/data:ro
      - ./output:/app/output
      - ./artifacts:/app/artifacts
      - ./markdown:/app/markdown
      - ./.cache:/app/.cache
      - ./config.yaml:/app/config.yaml:ro
    environment:
      - DOCVISION_CONFIG=/app/config.yaml
      - LOG_LEVEL=DEBUG
      - AZURE_DOC_INTELLIGENCE_ENDPOINT=${AZURE_DOC_INTELLIGENCE_ENDPOINT:-}
      - AZURE_DOC_INTELLIGENCE_KEY=${AZURE_DOC_INTELLIGENCE_KEY:-}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT:-}
      - AZURE_OPENAI_KEY=${AZURE_OPENAI_KEY:-}
    command: >
      python -m uvicorn docvision.web.app:app 
      --host 0.0.0.0 
      --port 8080 
      --reload
    profiles:
      - dev

  # Production server (CPU)
  docvision:
    build:
      context: .
      dockerfile: Dockerfile
    dns:
      - 8.8.8.8
      - 8.8.4.4
    ports:
      - "8080:8080"
    volumes:
      - ./data:/app/data:ro
      - ./output:/app/output
      - ./artifacts:/app/artifacts
      - ./markdown:/app/markdown
      - ./.cache:/app/.cache
      - ./config.yaml:/app/config.yaml:ro
      - docvision-models:/app/models
    environment:
      - DOCVISION_CONFIG=/app/config.yaml
      - LOG_LEVEL=INFO
      - AZURE_DOC_INTELLIGENCE_ENDPOINT=${AZURE_DOC_INTELLIGENCE_ENDPOINT:-}
      - AZURE_DOC_INTELLIGENCE_KEY=${AZURE_DOC_INTELLIGENCE_KEY:-}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT:-}
      - AZURE_OPENAI_KEY=${AZURE_OPENAI_KEY:-}
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "5"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Production server (GPU)
  docvision-gpu:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    ports:
      - "8080:8080"
    volumes:
      - ./data:/app/data:ro
      - ./output:/app/output
      - ./artifacts:/app/artifacts
      - ./markdown:/app/markdown
      - ./.cache:/app/.cache
      - ./config.yaml:/app/config.yaml:ro
      - docvision-models:/app/models
    environment:
      - DOCVISION_CONFIG=/app/config.yaml
      - LOG_LEVEL=INFO
      - NVIDIA_VISIBLE_DEVICES=all
      - AZURE_DOC_INTELLIGENCE_ENDPOINT=${AZURE_DOC_INTELLIGENCE_ENDPOINT:-}
      - AZURE_DOC_INTELLIGENCE_KEY=${AZURE_DOC_INTELLIGENCE_KEY:-}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT:-}
      - AZURE_OPENAI_KEY=${AZURE_OPENAI_KEY:-}
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 16G
    profiles:
      - gpu

  # Batch processing worker
  docvision-worker:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./data:/app/data:ro
      - ./output:/app/output
      - ./artifacts:/app/artifacts
      - ./markdown:/app/markdown
      - ./.cache:/app/.cache
      - ./config.yaml:/app/config.yaml:ro
      - docvision-models:/app/models
    environment:
      - DOCVISION_CONFIG=/app/config.yaml
      - AZURE_DOC_INTELLIGENCE_ENDPOINT=${AZURE_DOC_INTELLIGENCE_ENDPOINT:-}
      - AZURE_DOC_INTELLIGENCE_KEY=${AZURE_DOC_INTELLIGENCE_KEY:-}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT:-}
      - AZURE_OPENAI_KEY=${AZURE_OPENAI_KEY:-}
    command: >
      docvision batch /app/data 
      --output /app/output 
      --pattern "*.pdf" 
      --parallel
    profiles:
      - batch

volumes:
  docvision-models:
    driver: local
